{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/matthewgalligan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/matthewgalligan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "# Loading in the training data with Pandas\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "all_words = train['text'].str.split(expand=True).unstack().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [this, process, ,, however, ,, afforded, me, n...\n",
       "1        [it, never, once, occurred, to, me, that, the,...\n",
       "2        [in, his, left, hand, was, a, gold, snuff, box...\n",
       "3        [how, lovely, is, spring, as, we, looked, from...\n",
       "4        [finding, nothing, else, ,, not, even, gold, ,...\n",
       "5        [a, youth, passed, in, solitude, ,, my, best, ...\n",
       "6        [the, astronomer, ,, perhaps, ,, at, this, poi...\n",
       "7        [the, surcingle, hung, in, ribands, from, my, ...\n",
       "8        [i, knew, that, you, could, not, say, to, your...\n",
       "9        [i, confess, that, neither, the, structure, of...\n",
       "10       [he, shall, find, that, i, can, feel, my, inju...\n",
       "11       [here, we, barricaded, ourselves, ,, and, ,, f...\n",
       "12       [herbert, west, needed, fresh, bodies, because...\n",
       "13       [the, farm, like, grounds, extended, back, ver...\n",
       "14       [but, a, glance, will, show, the, fallacy, of,...\n",
       "15       [he, had, escaped, me, ,, and, i, must, commen...\n",
       "16       [to, these, speeches, they, gave, ,, of, cours...\n",
       "17       [her, native, sprightliness, needed, no, undue...\n",
       "18       [i, even, went, so, far, as, to, speak, of, a,...\n",
       "19       [his, facial, aspect, ,, too, ,, was, remarkab...\n",
       "20       [now, the, net, work, was, not, permanently, f...\n",
       "21       [it, was, not, that, the, sounds, were, hideou...\n",
       "22       [on, every, hand, was, a, wilderness, of, balc...\n",
       "23       [with, how, deep, a, spirit, of, wonder, and, ...\n",
       "24       [these, bizarre, attempts, at, explanation, we...\n",
       "25       [for, many, prodigies, and, signs, had, taken,...\n",
       "26       [all, that, as, yet, can, fairly, be, said, to...\n",
       "27       [i, seemed, to, be, upon, the, verge, of, comp...\n",
       "28       [our, compasses, ,, depth, gauges, ,, and, oth...\n",
       "29       [this, the, young, warriors, took, back, with,...\n",
       "                               ...                        \n",
       "19549    [but, it, was, not, so, ;, i, was, the, same, ...\n",
       "19550    [he, then, took, the, book, himself, ,, and, r...\n",
       "19551    [``, adolphe, le, bon, ,, clerk, to, mignaud, ...\n",
       "19552    [but, of, the, character, of, his, remarks, at...\n",
       "19553    [he, notes, every, variation, of, face, as, th...\n",
       "19554    [they, admitted, they, had, been, drunk, ,, bu...\n",
       "19555    [the, rays, of, the, newly, risen, sun, poured...\n",
       "19556    [to, the, north, on, the, craggy, precipice, a...\n",
       "19557    [the, frauds, of, the, banks, of, course, i, c...\n",
       "19558    [he, was, attired, ,, as, i, had, expected, ,,...\n",
       "19559    [when, a, fumbling, came, in, the, nearer, cas...\n",
       "19560    [but, then, there, is, the, tone, laconic, ,, ...\n",
       "19561    [average, people, in, society, and, business, ...\n",
       "19562    [the, modes, and, sources, of, this, kind, of,...\n",
       "19563    [yet, from, whom, has, not, that, rude, hand, ...\n",
       "19564    [almighty, god, no, ,, no, they, heard, they, ...\n",
       "19565    [i, hope, you, have, not, been, so, foolish, a...\n",
       "19566    [these, reflections, made, our, legislators, p...\n",
       "19567    [because, there, were, some, considerations, o...\n",
       "19568    [before, going, in, we, walked, up, the, stree...\n",
       "19569    [once, my, fancy, was, soothed, with, dreams, ...\n",
       "19570    [nay, ,, you, may, have, met, with, another, w...\n",
       "19571    [my, watch, was, still, going, ,, and, told, m...\n",
       "19572    [but, these, and, other, difficulties, attendi...\n",
       "19573    [stress, of, weather, drove, us, up, the, adri...\n",
       "19574    [i, could, have, fancied, ,, while, i, looked,...\n",
       "19575    [the, lids, clenched, themselves, together, as...\n",
       "19576    [mais, il, faut, agir, that, is, to, say, ,, a...\n",
       "19577    [for, an, item, of, news, like, this, ,, it, s...\n",
       "19578    [he, laid, a, gnarled, claw, on, my, shoulder,...\n",
       "Name: words, Length: 19579, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have a bunch of wonky punctuation that we need to fix, let's try again.\n",
    "\n",
    "train['words'] = train['text'].apply(lambda t: nltk.word_tokenize(str.lower(t))).values.tolist()\n",
    "train['words']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#remove stopwords\n",
    "punctuation = [',','.',';','?',':','``',\"''\",\"'\"]\n",
    "stopwords = stopwords  + punctuation\n",
    "\n",
    "train['words'] = train['words'].apply(lambda t: [word for word in t if word not in stopwords and len(word) > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one               1623\n",
       "upon              1411\n",
       "'s                1355\n",
       "could             1330\n",
       "would             1258\n",
       "man                777\n",
       "time               730\n",
       "yet                715\n",
       "said               704\n",
       "even               700\n",
       "might              629\n",
       "old                616\n",
       "like               613\n",
       "first              602\n",
       "must               597\n",
       "us                 596\n",
       "never              570\n",
       "life               569\n",
       "night              566\n",
       "made               565\n",
       "found              558\n",
       "seemed             544\n",
       "eyes               540\n",
       "every              535\n",
       "little             531\n",
       "day                523\n",
       "still              519\n",
       "great              511\n",
       "long               510\n",
       "saw                502\n",
       "                  ... \n",
       "godhead              1\n",
       "bankers              1\n",
       "fero                 1\n",
       "'offspring           1\n",
       "precociousness       1\n",
       "maguntinae           1\n",
       "benjamin             1\n",
       "insistently          1\n",
       "hecate               1\n",
       "warming              1\n",
       "walnut               1\n",
       "crossbones           1\n",
       "trammpled            1\n",
       "barkin               1\n",
       "materiality          1\n",
       "composer             1\n",
       "agreable             1\n",
       "zath                 1\n",
       "shatter              1\n",
       "invite               1\n",
       "aesculapius          1\n",
       "referable            1\n",
       "fourthly             1\n",
       "mss.                 1\n",
       "awakeness            1\n",
       "fours                1\n",
       "exonerated           1\n",
       "comus                1\n",
       "bxg                  1\n",
       "teetotum             1\n",
       "Length: 25226, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all the words into a series and show the value counts of all the various words.\n",
    "slist = []\n",
    "for x in train['words']:\n",
    "        slist.extend(x)\n",
    "\n",
    "all_words = pd.Series(slist)\n",
    "counts = all_words.value_counts()\n",
    "#The most common word is still a blank string, and I'm not sure why this is an issue.\n",
    "counts\n",
    "\n",
    "#Train for bucket of words\n",
    "\n",
    "#Train for categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save shape for splitting later\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "\n",
    "# Get subset of data for each author\n",
    "train_EAP = train[train.author.isin(['EAP'])]\n",
    "train_MWS = train[train.author.isin(['MWS'])]\n",
    "train_HPL = train[train.author.isin(['HPL'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              process\n",
       "1              however\n",
       "2             afforded\n",
       "3                means\n",
       "4         ascertaining\n",
       "5           dimensions\n",
       "6              dungeon\n",
       "7                might\n",
       "8                 make\n",
       "9              circuit\n",
       "10              return\n",
       "11               point\n",
       "12              whence\n",
       "13                 set\n",
       "14             without\n",
       "15               aware\n",
       "16                fact\n",
       "17           perfectly\n",
       "18             uniform\n",
       "19              seemed\n",
       "20                wall\n",
       "21               never\n",
       "22            occurred\n",
       "23            fumbling\n",
       "24               might\n",
       "25                mere\n",
       "26             mistake\n",
       "27                left\n",
       "28                hand\n",
       "29                gold\n",
       "              ...     \n",
       "257872           built\n",
       "257873           brush\n",
       "257874            lids\n",
       "257875        clenched\n",
       "257876        together\n",
       "257877           spasm\n",
       "257878            mais\n",
       "257879              il\n",
       "257880            faut\n",
       "257881            agir\n",
       "257882             say\n",
       "257883       frenchman\n",
       "257884           never\n",
       "257885          faints\n",
       "257886        outright\n",
       "257887            item\n",
       "257888            news\n",
       "257889            like\n",
       "257890         strikes\n",
       "257891              us\n",
       "257892          coolly\n",
       "257893        received\n",
       "257894            laid\n",
       "257895         gnarled\n",
       "257896            claw\n",
       "257897        shoulder\n",
       "257898          seemed\n",
       "257899         shaking\n",
       "257900      altogether\n",
       "257901           mirth\n",
       "Length: 257902, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get one-hot encoding\n",
    "author_one_hot = pd.get_dummies(train['author'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 28)\t1\n",
      "  (0, 64)\t1\n",
      "  (0, 65)\t1\n",
      "  (0, 66)\t1\n",
      "  (0, 67)\t1\n",
      "  (0, 68)\t1\n",
      "  (0, 69)\t1\n",
      "  (0, 70)\t1\n",
      "  (0, 71)\t1\n",
      "  (0, 72)\t1\n",
      "  (0, 73)\t1\n",
      "  (0, 74)\t1\n",
      "  (0, 75)\t1\n",
      "  (0, 76)\t1\n",
      "  (0, 77)\t1\n",
      "  (0, 78)\t1\n"
     ]
    }
   ],
   "source": [
    "unique_words = all_words.unique()\n",
    "cv = CountVectorizer(vocabulary=unique_words)\n",
    "output = cv.fit_transform(train['text'])\n",
    "out_arr = output\n",
    "#st = vec.fit_transform(train['words'])\n",
    "#st\n",
    "\n",
    "print(out_arr[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
