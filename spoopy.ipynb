{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\matth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\matth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "# Loading in the training data with Pandas\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "all_words = train['text'].str.split(expand=True).unstack().value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [this, process, ,, however, ,, afforded, me, n...\n",
       "1        [it, never, once, occurred, to, me, that, the,...\n",
       "2        [in, his, left, hand, was, a, gold, snuff, box...\n",
       "3        [how, lovely, is, spring, as, we, looked, from...\n",
       "4        [finding, nothing, else, ,, not, even, gold, ,...\n",
       "5        [a, youth, passed, in, solitude, ,, my, best, ...\n",
       "6        [the, astronomer, ,, perhaps, ,, at, this, poi...\n",
       "7        [the, surcingle, hung, in, ribands, from, my, ...\n",
       "8        [i, knew, that, you, could, not, say, to, your...\n",
       "9        [i, confess, that, neither, the, structure, of...\n",
       "10       [he, shall, find, that, i, can, feel, my, inju...\n",
       "11       [here, we, barricaded, ourselves, ,, and, ,, f...\n",
       "12       [herbert, west, needed, fresh, bodies, because...\n",
       "13       [the, farm, like, grounds, extended, back, ver...\n",
       "14       [but, a, glance, will, show, the, fallacy, of,...\n",
       "15       [he, had, escaped, me, ,, and, i, must, commen...\n",
       "16       [to, these, speeches, they, gave, ,, of, cours...\n",
       "17       [her, native, sprightliness, needed, no, undue...\n",
       "18       [i, even, went, so, far, as, to, speak, of, a,...\n",
       "19       [his, facial, aspect, ,, too, ,, was, remarkab...\n",
       "20       [now, the, net, work, was, not, permanently, f...\n",
       "21       [it, was, not, that, the, sounds, were, hideou...\n",
       "22       [on, every, hand, was, a, wilderness, of, balc...\n",
       "23       [with, how, deep, a, spirit, of, wonder, and, ...\n",
       "24       [these, bizarre, attempts, at, explanation, we...\n",
       "25       [for, many, prodigies, and, signs, had, taken,...\n",
       "26       [all, that, as, yet, can, fairly, be, said, to...\n",
       "27       [i, seemed, to, be, upon, the, verge, of, comp...\n",
       "28       [our, compasses, ,, depth, gauges, ,, and, oth...\n",
       "29       [this, the, young, warriors, took, back, with,...\n",
       "                               ...                        \n",
       "19549    [but, it, was, not, so, ;, i, was, the, same, ...\n",
       "19550    [he, then, took, the, book, himself, ,, and, r...\n",
       "19551    [``, adolphe, le, bon, ,, clerk, to, mignaud, ...\n",
       "19552    [but, of, the, character, of, his, remarks, at...\n",
       "19553    [he, notes, every, variation, of, face, as, th...\n",
       "19554    [they, admitted, they, had, been, drunk, ,, bu...\n",
       "19555    [the, rays, of, the, newly, risen, sun, poured...\n",
       "19556    [to, the, north, on, the, craggy, precipice, a...\n",
       "19557    [the, frauds, of, the, banks, of, course, i, c...\n",
       "19558    [he, was, attired, ,, as, i, had, expected, ,,...\n",
       "19559    [when, a, fumbling, came, in, the, nearer, cas...\n",
       "19560    [but, then, there, is, the, tone, laconic, ,, ...\n",
       "19561    [average, people, in, society, and, business, ...\n",
       "19562    [the, modes, and, sources, of, this, kind, of,...\n",
       "19563    [yet, from, whom, has, not, that, rude, hand, ...\n",
       "19564    [almighty, god, no, ,, no, they, heard, they, ...\n",
       "19565    [i, hope, you, have, not, been, so, foolish, a...\n",
       "19566    [these, reflections, made, our, legislators, p...\n",
       "19567    [because, there, were, some, considerations, o...\n",
       "19568    [before, going, in, we, walked, up, the, stree...\n",
       "19569    [once, my, fancy, was, soothed, with, dreams, ...\n",
       "19570    [nay, ,, you, may, have, met, with, another, w...\n",
       "19571    [my, watch, was, still, going, ,, and, told, m...\n",
       "19572    [but, these, and, other, difficulties, attendi...\n",
       "19573    [stress, of, weather, drove, us, up, the, adri...\n",
       "19574    [i, could, have, fancied, ,, while, i, looked,...\n",
       "19575    [the, lids, clenched, themselves, together, as...\n",
       "19576    [mais, il, faut, agir, that, is, to, say, ,, a...\n",
       "19577    [for, an, item, of, news, like, this, ,, it, s...\n",
       "19578    [he, laid, a, gnarled, claw, on, my, shoulder,...\n",
       "Name: words, Length: 19579, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have a bunch of wonky punctuation that we need to fix, let's try again.\n",
    "\n",
    "train['words'] = train['text'].apply(lambda t: nltk.word_tokenize(str.lower(t))).values.tolist()\n",
    "train['words']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#remove stopwords\n",
    "punctuation = [',','.',';','?',':','``',\"''\",\"'\"]\n",
    "stopwords = stopwords  + punctuation\n",
    "\n",
    "train['words'] = train['words'].apply(lambda t: [word for word in t if word not in stopwords and len(word) > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one              1623\n",
       "upon             1411\n",
       "'s               1355\n",
       "could            1330\n",
       "would            1258\n",
       "man               777\n",
       "time              730\n",
       "yet               715\n",
       "said              704\n",
       "even              700\n",
       "might             629\n",
       "old               616\n",
       "like              613\n",
       "first             602\n",
       "must              597\n",
       "us                596\n",
       "never             570\n",
       "life              569\n",
       "night             566\n",
       "made              565\n",
       "found             558\n",
       "seemed            544\n",
       "eyes              540\n",
       "every             535\n",
       "little            531\n",
       "day               523\n",
       "still             519\n",
       "great             511\n",
       "long              510\n",
       "saw               502\n",
       "                 ... \n",
       "overcrowded         1\n",
       "parmly              1\n",
       "vagary              1\n",
       "alp                 1\n",
       "tackle              1\n",
       "meas                1\n",
       "scuffling           1\n",
       "blueness            1\n",
       "supporter           1\n",
       "inappreciable       1\n",
       "haousekeeper        1\n",
       "quivers             1\n",
       "'all                1\n",
       "waiters             1\n",
       "seedy               1\n",
       "oceanographic       1\n",
       "unsubdued           1\n",
       "flatzplatz          1\n",
       "helvius             1\n",
       "obtruded            1\n",
       "postage             1\n",
       "rubini              1\n",
       "undertakers         1\n",
       "immerse             1\n",
       "tracery             1\n",
       "'ah                 1\n",
       "unattractive        1\n",
       "timon               1\n",
       "grazed              1\n",
       "titter              1\n",
       "Length: 25226, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all the words into a series and show the value counts of all the various words.\n",
    "slist = []\n",
    "for x in train['words']:\n",
    "        slist.extend(x)\n",
    "\n",
    "all_words = pd.Series(slist)\n",
    "counts = all_words.value_counts()\n",
    "#The most common word is still a blank string, and I'm not sure why this is an issue.\n",
    "counts\n",
    "\n",
    "#Train for bucket of words\n",
    "\n",
    "#Train for categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save shape for splitting later\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "\n",
    "# Get subset of data for each author\n",
    "train_EAP = train[train.author.isin(['EAP'])]\n",
    "train_MWS = train[train.author.isin(['MWS'])]\n",
    "train_HPL = train[train.author.isin(['HPL'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one-hot encoding\n",
    "author_one_hot = pd.get_dummies(train['author'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 28)\t1\n",
      "  (0, 64)\t1\n",
      "  (0, 65)\t1\n",
      "  (0, 66)\t1\n",
      "  (0, 67)\t1\n",
      "  (0, 68)\t1\n",
      "  (0, 69)\t1\n",
      "  (0, 70)\t1\n",
      "  (0, 71)\t1\n",
      "  (0, 72)\t1\n",
      "  (0, 73)\t1\n",
      "  (0, 74)\t1\n",
      "  (0, 75)\t1\n",
      "  (0, 76)\t1\n",
      "  (0, 77)\t1\n",
      "  (0, 78)\t1\n"
     ]
    }
   ],
   "source": [
    "#Make a vector from all words bucket\n",
    "\n",
    "unique_words = all_words.unique()\n",
    "cv = CountVectorizer(vocabulary=unique_words)\n",
    "output = cv.fit_transform(train['text'])\n",
    "out_arr = output\n",
    "#st = vec.fit_transform(train['words'])\n",
    "#st\n",
    "\n",
    "print(out_arr[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, at this point, I have a matrix of each individual word for each row in train['text'] it is in the var output\n",
    "\n",
    "From here, I can do regular old regression against the various authors (one at a time, I presume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25216</th>\n",
       "      <th>25217</th>\n",
       "      <th>25218</th>\n",
       "      <th>25219</th>\n",
       "      <th>25220</th>\n",
       "      <th>25221</th>\n",
       "      <th>25222</th>\n",
       "      <th>25223</th>\n",
       "      <th>25224</th>\n",
       "      <th>25225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      \\\n",
       "0      1      1      1      1      1      1      1      1      1      1   \n",
       "1      0      0      0      0      0      0      0      1      0      0   \n",
       "2      0      0      0      0      0      0      0      0      0      0   \n",
       "3      0      0      0      0      0      0      0      0      0      0   \n",
       "4      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   ...    25216  25217  25218  25219  25220  25221  25222  25223  25224  25225  \n",
       "0  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "1  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "2  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "3  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "4  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 25226 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix = pd.DataFrame(output.toarray())\n",
    "#train_matrix['id'] = train['id']\n",
    "\n",
    "\n",
    "#Now, I have a training matrix with everything, but the author isn't categorized out yet.\n",
    "train_matrix[0:5]\n",
    "\n",
    "#I want to get three separate models for guessing EAP, MHS, HPL, and setup three separate matrixes to do so.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    2\n",
      "2    0\n",
      "3    1\n",
      "4    2\n",
      "5    1\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    1\n",
      "Name: author, dtype: int64\n",
      "0    EAP\n",
      "1    HPL\n",
      "2    EAP\n",
      "3    MWS\n",
      "4    HPL\n",
      "5    MWS\n",
      "6    EAP\n",
      "7    EAP\n",
      "8    EAP\n",
      "9    MWS\n",
      "Name: author, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25216</th>\n",
       "      <th>25217</th>\n",
       "      <th>25218</th>\n",
       "      <th>25219</th>\n",
       "      <th>25220</th>\n",
       "      <th>25221</th>\n",
       "      <th>25222</th>\n",
       "      <th>25223</th>\n",
       "      <th>25224</th>\n",
       "      <th>25225</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      \\\n",
       "0      1      1      1      1      1      1      1      1      1      1   \n",
       "1      0      0      0      0      0      0      0      1      0      0   \n",
       "2      0      0      0      0      0      0      0      0      0      0   \n",
       "3      0      0      0      0      0      0      0      0      0      0   \n",
       "4      0      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "   ...    25216  25217  25218  25219  25220  25221  25222  25223  25224  25225  \n",
       "0  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "1  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "2  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "3  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "4  ...        0      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 25226 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "y_values = pd.DataFrame()    \n",
    "y_values['author'] = train['author'].apply(lambda t: 0 if t == 'EAP' else (1 if t == 'MWS' else 2))    \n",
    "print(y_values['author'][0:10])\n",
    "print(train['author'][0:10])\n",
    "train_matrix[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok! We have a working input matrix that looks right for words and authors. we use xgboost with binary:logistics and predict_prob to get probability from our non-scalar author values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
